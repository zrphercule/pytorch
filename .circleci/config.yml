# IMPORTANT: To update Docker image version, please search and update ":{previous_version}"
# in this file to the new version number, and **ALSO** update the version number below:
# PyTorchDockerVersion:251
# Caffe2DockerVersion:213

docker_config_defaults: &docker_config_defaults
  user: jenkins
  aws_auth:
    # This IAM user only allows read-write access to ECR
    aws_access_key_id: ${CIRCLECI_AWS_ACCESS_KEY_FOR_ECR_READ_WRITE_V2}
    aws_secret_access_key: ${CIRCLECI_AWS_SECRET_KEY_FOR_ECR_READ_WRITE_V2}

# NOTE: We only perform the merge in build step and not in test step, because
# all source files will be shared from build to test
merge_pull_request_onto_master: &merge_pull_request_onto_master
  name: Merge Onto Master
  command: |
    set -ex
    if [[ "${CIRCLE_BRANCH}" != "master" ]]; then
      git config --global user.email "circleci.ossci@gmail.com"
      git config --global user.name "CircleCI"

      git config remote.origin.url https://github.com/pytorch/pytorch.git
      git config --add remote.origin.fetch +refs/heads/master:refs/remotes/origin/master
      git fetch --tags --progress https://github.com/pytorch/pytorch.git +refs/heads/master:refs/remotes/origin/master --quiet
      if [[ "${CIRCLE_BRANCH}" == pull/* ]]; then  # if this is a forked PR
        git fetch --tags --progress https://github.com/pytorch/pytorch.git +refs/${CIRCLE_BRANCH}/head:refs/remotes/origin/${CIRCLE_BRANCH}
      else
        git fetch --tags --progress https://github.com/pytorch/pytorch.git +refs/heads/${CIRCLE_BRANCH}:refs/remotes/origin/${CIRCLE_BRANCH}
      fi

      export GIT_MERGE_TARGET=`git log -n 1 --pretty=format:"%H" origin/master`
      echo "GIT_MERGE_TARGET: " ${GIT_MERGE_TARGET}
      export GIT_COMMIT=${CIRCLE_SHA1}
      echo "GIT_COMMIT: " ${GIT_COMMIT}

      git merge --no-edit --no-ff ${GIT_MERGE_TARGET}
    fi

install_official_git_client: &install_official_git_client
  name: Install Official Git Client
  no_output_timeout: "1h"
  command: |
    set -e
    sudo apt-get update
    sudo apt-get install -y openssh-client git

setup_ci_environment: &setup_ci_environment
  name: Set Up CI Environment
  no_output_timeout: "1h"
  command: |
    set -e
    sudo pip install awscli==1.16.35

    sudo apt-get update
    sudo apt-get remove linux-image-generic linux-headers-generic linux-generic
    sudo apt-get install linux-headers-$(uname -r)
    sudo apt-get install linux-image-generic
    sudo apt-get install -y moreutils

    curl -L https://nvidia.github.io/nvidia-docker/gpgkey | sudo apt-key add -
    echo "deb https://nvidia.github.io/libnvidia-container/ubuntu14.04/amd64 /" | sudo tee -a /etc/apt/sources.list.d/nvidia-docker.list
    echo "deb https://nvidia.github.io/nvidia-container-runtime/ubuntu14.04/amd64 /" | sudo tee -a /etc/apt/sources.list.d/nvidia-docker.list
    echo "deb https://nvidia.github.io/nvidia-docker/ubuntu14.04/amd64 /" | sudo tee -a /etc/apt/sources.list.d/nvidia-docker.list
    sudo apt-get update
    sudo apt-get install -y nvidia-docker2
    sudo pkill -SIGHUP dockerd

    if [[ "${JOB_BASE_NAME}" == *-test* ]]; then
      if [ -n "${CUDA_VERSION}" ]; then
        wget 'https://s3.amazonaws.com/ossci-linux/nvidia_driver/NVIDIA-Linux-x86_64-396.26.run'
        sudo /bin/bash ./NVIDIA-Linux-x86_64-396.26.run -s --no-drm
        nvidia-smi
      fi
    fi

    if [[ "${JOB_BASE_NAME}" == *-build ]]; then
      echo "declare -x IN_CIRCLECI=1" > /home/circleci/project/env
      echo "declare -x COMMIT_SOURCE=${CIRCLE_BRANCH}" >> /home/circleci/project/env
      echo "declare -x PYTHON_VERSION=${PYTHON_VERSION}" >> /home/circleci/project/env
      echo "declare -x SCCACHE_BUCKET=ossci-compiler-cache-circleci-v2" >> /home/circleci/project/env
      if [ -n "${CUDA_VERSION}" ]; then
        echo "declare -x TORCH_CUDA_ARCH_LIST=5.2" >> /home/circleci/project/env
      fi
      export SCCACHE_MAX_JOBS=`expr $(nproc) - 1`
      export MEMORY_LIMIT_MAX_JOBS=8  # the "large" resource class on CircleCI has 32 CPU cores, if we use all of them we'll OOM
      export MAX_JOBS=$(( ${SCCACHE_MAX_JOBS} > ${MEMORY_LIMIT_MAX_JOBS} ? ${MEMORY_LIMIT_MAX_JOBS} : ${SCCACHE_MAX_JOBS} ))
      echo "declare -x MAX_JOBS=${MAX_JOBS}" >> /home/circleci/project/env

      # This IAM user allows write access to S3 bucket for sccache
      echo "declare -x AWS_ACCESS_KEY_ID=${CIRCLECI_AWS_ACCESS_KEY_FOR_SCCACHE_S3_BUCKET_V2}" >> /home/circleci/project/env
      echo "declare -x AWS_SECRET_ACCESS_KEY=${CIRCLECI_AWS_SECRET_KEY_FOR_SCCACHE_S3_BUCKET_V2}" >> /home/circleci/project/env
    fi

    # This IAM user only allows read-write access to ECR
    export AWS_ACCESS_KEY_ID=${CIRCLECI_AWS_ACCESS_KEY_FOR_ECR_READ_WRITE_V2}
    export AWS_SECRET_ACCESS_KEY=${CIRCLECI_AWS_SECRET_KEY_FOR_ECR_READ_WRITE_V2}
    eval $(aws ecr get-login --region us-east-1 --no-include-email)

pytorch_linux_cpu_build_test_defaults: &pytorch_linux_cpu_build_test_defaults
  resource_class: large
  working_directory: /var/lib/jenkins/workspace
  steps:
  - run:
      <<: *install_official_git_client
  - checkout
  - run:
      <<: *merge_pull_request_onto_master
  - run:
      name: Build And Test
      no_output_timeout: "1h"
      command: |
        set -e
        sudo apt-get update
        sudo apt-get install -y moreutils

        export IN_CIRCLECI=1
        export COMMIT_SOURCE=${CIRCLE_BRANCH}
        export SCCACHE_BUCKET=ossci-compiler-cache-circleci-v2
        export SCCACHE_MAX_JOBS=`expr $(nproc) - 1`
        export MEMORY_LIMIT_MAX_JOBS=8  # the "large" resource class on CircleCI has 32 CPU cores, if we use all of them we'll OOM
        export MAX_JOBS=$(( ${SCCACHE_MAX_JOBS} > ${MEMORY_LIMIT_MAX_JOBS} ? ${MEMORY_LIMIT_MAX_JOBS} : ${SCCACHE_MAX_JOBS} ))
        # This IAM user allows write access to S3 bucket for sccache
        export AWS_ACCESS_KEY_ID=${CIRCLECI_AWS_ACCESS_KEY_FOR_SCCACHE_S3_BUCKET_V2}
        export AWS_SECRET_ACCESS_KEY=${CIRCLECI_AWS_SECRET_KEY_FOR_SCCACHE_S3_BUCKET_V2}
        git submodule sync && git submodule update --init
        .jenkins/pytorch/build.sh 2>&1 | ts
        .jenkins/pytorch/test.sh 2>&1 | ts

pytorch_linux_build_defaults: &pytorch_linux_build_defaults
  resource_class: large
  machine:
    image: default
  steps:
  - run:
      <<: *install_official_git_client
  - checkout
  - run:
      <<: *merge_pull_request_onto_master
  - run:
      <<: *setup_ci_environment
  - run:
      name: Build
      no_output_timeout: "1h"
      command: |
        set -e
        # Pull Docker image and run build
        echo "DOCKER_IMAGE: "${DOCKER_IMAGE}
        docker pull ${DOCKER_IMAGE}
        export id=$(docker run -t -d -w /var/lib/jenkins ${DOCKER_IMAGE})

        git submodule sync && git submodule update --init

        docker cp /home/circleci/project/. $id:/var/lib/jenkins/workspace

        ((echo "export JOB_BASE_NAME=${JOB_BASE_NAME}" && echo "source ./workspace/env" && echo 'sudo chown -R jenkins workspace && cd workspace && .jenkins/pytorch/build.sh') | docker exec -u jenkins -i "$id" bash) 2>&1 | ts

        # Push intermediate Docker image and save COMMIT_DOCKER_IMAGE for next phase to use
        mkdir -p /home/circleci/project/pytorch-ci-env
        touch /home/circleci/project/pytorch-ci-env/.tmp  # Dummy file so that the persist_to_workspace step won't complain about not finding any file

        if [ -z "${BUILD_ONLY}" ]; then
          export COMMIT_DOCKER_IMAGE=${DOCKER_IMAGE}-${CIRCLE_SHA1}
          docker commit "$id" ${COMMIT_DOCKER_IMAGE}
          docker push ${COMMIT_DOCKER_IMAGE}
          echo "declare -x COMMIT_DOCKER_IMAGE=${COMMIT_DOCKER_IMAGE}" > /home/circleci/project/pytorch-ci-env/COMMIT_DOCKER_IMAGE
        fi
  - persist_to_workspace:
      root: /home/circleci/project/pytorch-ci-env
      paths:
        - "*"

pytorch_linux_test_defaults: &pytorch_linux_test_defaults
  machine:
    image: default
  steps:
  - run:
      name: Prepare workspace
      command: |
        sudo mkdir -p /home/circleci/project/pytorch-ci-env
        sudo chmod -R 777 /home/circleci/project/pytorch-ci-env
  - attach_workspace:
      at: /home/circleci/project/pytorch-ci-env
  - run:
      <<: *setup_ci_environment
  - run:
      name: Test
      no_output_timeout: "1h"
      command: |
        set -e
        source /home/circleci/project/pytorch-ci-env/COMMIT_DOCKER_IMAGE
        echo "DOCKER_IMAGE: "${COMMIT_DOCKER_IMAGE}
        docker pull ${COMMIT_DOCKER_IMAGE}
        if [ -n "${CUDA_VERSION}" ]; then
          id=$(docker run --runtime=nvidia -t -d -w /var/lib/jenkins ${COMMIT_DOCKER_IMAGE})
        else
          id=$(docker run -t -d -w /var/lib/jenkins ${COMMIT_DOCKER_IMAGE})
        fi
        if [ -n "${MULTI_GPU}" ]; then
          ((echo "export JOB_BASE_NAME=${JOB_BASE_NAME}" && echo "source ./workspace/env" && echo 'sudo chown -R jenkins workspace && cd workspace && .jenkins/pytorch/multigpu-test.sh') | docker exec -u jenkins -i "$id" bash) 2>&1 | ts
        else
          ((echo "export JOB_BASE_NAME=${JOB_BASE_NAME}" && echo "source ./workspace/env" && echo 'sudo chown -R jenkins workspace && cd workspace && .jenkins/pytorch/test.sh') | docker exec -u jenkins -i "$id" bash) 2>&1 | ts
        fi

caffe2_linux_build_defaults: &caffe2_linux_build_defaults
  resource_class: large
  machine:
    image: default
  steps:
  - run:
      <<: *install_official_git_client
  - checkout
  - run:
      <<: *merge_pull_request_onto_master
  - run:
      <<: *setup_ci_environment
  - run:
      name: Build
      no_output_timeout: "1h"
      command: |
        set -e
        # TODO: merge this into Caffe2 build.sh
        cat >/home/circleci/project/ci_build_script.sh <<EOL
        # =================== The following code will be executed inside Docker container ===================
        set -ex

        # Need to checkout fetch PRs for onnxbot tracking PRs
        git submodule update --init third_party/onnx || true
        cd third_party/onnx && git fetch --tags --progress origin +refs/pull/*:refs/remotes/origin/pr/* && cd -

        # Reinitialize submodules
        git submodule sync && git submodule update --init --recursive

        mkdir -p build

        # Configure additional cmake arguments
        cmake_args=()
        cmake_args+=("$CMAKE_ARGS")

        if [[ $BUILD_ENVIRONMENT == *aten* ]]; then
          cmake_args+=("-DBUILD_ATEN=ON")
        fi

        # conda must be added to the path for Anaconda builds (this location must be
        # the same as that in install_anaconda.sh used to build the docker image)
        if [[ "${BUILD_ENVIRONMENT}" == conda* ]]; then
          export PATH=/opt/conda/bin:$PATH
          sudo chown -R jenkins:jenkins '/opt/conda'
        fi

        # set the env var for onnx build and test
        if [[ "$BUILD_ENVIRONMENT" == *onnx* ]]; then
          export INTEGRATED=1
        fi

        # Build
        if test -x ".jenkins/caffe2/build.sh"; then
          ./.jenkins/caffe2/build.sh ${cmake_args[@]}
        else
          ./.jenkins/build.sh ${cmake_args[@]}
        fi

        # Show sccache stats if it is running
        if pgrep sccache > /dev/null; then
          sccache --show-stats
        fi
        # =================== The above code will be executed inside Docker container ===================
        EOL
        chmod +x /home/circleci/project/ci_build_script.sh

        echo "DOCKER_IMAGE: "${DOCKER_IMAGE}
        docker pull ${DOCKER_IMAGE}
        export id=$(docker run -t -d -w /var/lib/jenkins ${DOCKER_IMAGE})
        docker cp /home/circleci/project/. $id:/var/lib/jenkins/workspace

        ((echo "source ./workspace/env" && echo 'sudo chown -R jenkins workspace && cd workspace && ./ci_build_script.sh') | docker exec -u jenkins -i "$id" bash) 2>&1 | ts

        mkdir -p /home/circleci/project/caffe2-ci-env
        touch /home/circleci/project/caffe2-ci-env/.tmp  # Dummy file so that the persist_to_workspace step won't complain about not finding any file

        if [ -z "${BUILD_ONLY}" ]; then
          export COMMIT_DOCKER_IMAGE=${DOCKER_IMAGE}-${CIRCLE_SHA1}
          docker commit "$id" ${COMMIT_DOCKER_IMAGE}
          docker push ${COMMIT_DOCKER_IMAGE}
          echo "declare -x COMMIT_DOCKER_IMAGE=${COMMIT_DOCKER_IMAGE}" > /home/circleci/project/caffe2-ci-env/COMMIT_DOCKER_IMAGE
        fi
  - persist_to_workspace:
      root: /home/circleci/project/caffe2-ci-env
      paths:
        - "*"

caffe2_linux_test_defaults: &caffe2_linux_test_defaults
  machine:
    image: default
  steps:
  - run:
      name: Prepare workspace
      command: |
        sudo mkdir -p /home/circleci/project/caffe2-ci-env
        sudo chmod -R 777 /home/circleci/project/caffe2-ci-env
  - attach_workspace:
      at: /home/circleci/project/caffe2-ci-env
  - run:
      <<: *setup_ci_environment
  - run:
      name: Test
      no_output_timeout: "1h"
      command: |
        set -e
        # TODO: merge this into Caffe2 test.sh
        cat >/home/circleci/project/ci_test_script.sh <<EOL
        # =================== The following code will be executed inside Docker container ===================
        set -ex

        # libdc1394 (dependency of OpenCV) expects /dev/raw1394 to exist...
        sudo ln /dev/null /dev/raw1394

        # Hotfix, use hypothesis 3.44.6 on Ubuntu 14.04
        # See comments on https://github.com/HypothesisWorks/hypothesis-python/commit/eadd62e467d6cee6216e71b391951ec25b4f5830
        if [[ "$BUILD_ENVIRONMENT" == *ubuntu14.04* ]]; then
          sudo pip uninstall -y hypothesis
          # "pip install hypothesis==3.44.6" from official server is unreliable on CircleCI, so we host a copy on S3 instead
          sudo pip install attrs -f https://s3.amazonaws.com/ossci-linux/wheels/attrs-18.1.0-py2.py3-none-any.whl
          sudo pip install coverage -f https://s3.amazonaws.com/ossci-linux/wheels/coverage-4.5.1-cp36-cp36m-macosx_10_12_x86_64.whl
          sudo pip install hypothesis -f https://s3.amazonaws.com/ossci-linux/wheels/hypothesis-3.44.6-py3-none-any.whl
        fi

        # conda must be added to the path for Anaconda builds (this location must be
        # the same as that in install_anaconda.sh used to build the docker image)
        if [[ "${BUILD_ENVIRONMENT}" == conda* ]]; then
          export PATH=/opt/conda/bin:$PATH
        fi

        # set the env var for onnx build and test
        if [[ "$BUILD_ENVIRONMENT" == *onnx* ]]; then
          export INTEGRATED=1
        fi

        # Upgrade SSL module to avoid old SSL warnings
        pip install --user --upgrade pyOpenSSL ndg-httpsclient pyasn1

        pip install --user -b /tmp/pip_install_onnx "file:///var/lib/jenkins/workspace/third_party/onnx#egg=onnx"
        pip install --user future

        # Build
        if test -x ".jenkins/caffe2/test.sh"; then
          ./.jenkins/caffe2/test.sh
        else
          ./.jenkins/test.sh
        fi

        # Remove benign core dumps.
        # These are tests for signal handling (including SIGABRT).
        rm -f ./crash/core.fatal_signal_as.*
        rm -f ./crash/core.logging_test.*
        # =================== The above code will be executed inside Docker container ===================
        EOL
        chmod +x /home/circleci/project/ci_test_script.sh

        source /home/circleci/project/caffe2-ci-env/COMMIT_DOCKER_IMAGE
        echo "DOCKER_IMAGE: "${COMMIT_DOCKER_IMAGE}
        docker pull ${COMMIT_DOCKER_IMAGE}
        if [ -n "${CUDA_VERSION}" ]; then
          id=$(docker run --runtime=nvidia -t -d -w /var/lib/jenkins ${COMMIT_DOCKER_IMAGE})
        else
          id=$(docker run -t -d -w /var/lib/jenkins ${COMMIT_DOCKER_IMAGE})
        fi
        docker cp /home/circleci/project/. "$id:/var/lib/jenkins/workspace"

        ((echo "source ./workspace/env" && echo 'sudo chown -R jenkins workspace && cd workspace && ./ci_test_script.sh') | docker exec -u jenkins -i "$id" bash) 2>&1 | ts

caffe2_macos_build_defaults: &caffe2_macos_build_defaults
  macos:
    xcode: "9.0"
  steps:
    - checkout
    - run:
        <<: *merge_pull_request_onto_master
    - run:
        name: Build
        no_output_timeout: "1h"
        command: |
          set -e

          export IN_CIRCLECI=1

          brew install moreutils
          brew install cmake

          # Reinitialize submodules
          git submodule sync && git submodule update --init --recursive

          # Reinitialize path (see man page for path_helper(8))
          eval `/usr/libexec/path_helper -s`

          # Use Homebrew Python if configured to do so
          if [ "${PYTHON_INSTALLATION}" == "homebrew" ]; then
            export PATH=/usr/local/opt/python/libexec/bin:/usr/local/bin:$PATH
          fi

          pip install numpy

          # Install Anaconda if we need to
          if [ -n "${CAFFE2_USE_ANACONDA}" ]; then
            rm -rf ${TMPDIR}/anaconda
            curl -o ${TMPDIR}/anaconda.sh https://repo.continuum.io/miniconda/Miniconda${ANACONDA_VERSION}-latest-MacOSX-x86_64.sh
            /bin/bash ${TMPDIR}/anaconda.sh -b -p ${TMPDIR}/anaconda
            rm -f ${TMPDIR}/anaconda.sh
            export PATH="${TMPDIR}/anaconda/bin:${PATH}"
            source ${TMPDIR}/anaconda/bin/activate
          fi

          # Install sccache
          sudo curl https://s3.amazonaws.com/ossci-macos/sccache --output /usr/local/bin/sccache
          sudo chmod +x /usr/local/bin/sccache
          export SCCACHE_BUCKET=ossci-compiler-cache-circleci-v2

          # This IAM user allows write access to S3 bucket for sccache
          export AWS_ACCESS_KEY_ID=${CIRCLECI_AWS_ACCESS_KEY_FOR_SCCACHE_S3_BUCKET_V2}
          export AWS_SECRET_ACCESS_KEY=${CIRCLECI_AWS_SECRET_KEY_FOR_SCCACHE_S3_BUCKET_V2}

          export SCCACHE_BIN=${PWD}/sccache_bin
          mkdir -p ${SCCACHE_BIN}
          if which sccache > /dev/null; then
            printf "#!/bin/sh\nexec sccache $(which clang++) \$*" > "${SCCACHE_BIN}/clang++"
            chmod a+x "${SCCACHE_BIN}/clang++"

            printf "#!/bin/sh\nexec sccache $(which clang) \$*" > "${SCCACHE_BIN}/clang"
            chmod a+x "${SCCACHE_BIN}/clang"

            export PATH="${SCCACHE_BIN}:$PATH"
          fi

          # Build
          if [ "${BUILD_IOS:-0}" -eq 1 ]; then
            scripts/build_ios.sh 2>&1 | ts
          elif [ -n "${CAFFE2_USE_ANACONDA}" ]; then
            # All conda build logic should be in scripts/build_anaconda.sh
            scripts/build_anaconda.sh 2>&1 | ts
          else
            scripts/build_local.sh 2>&1 | ts
          fi

          # Show sccache stats if it is running
          if which sccache > /dev/null; then
            sccache --show-stats
          fi

version: 2
jobs:
  pytorch_linux_trusty_py2_7_9_build_test:
    docker:
      - image: 308535385114.dkr.ecr.us-east-1.amazonaws.com/pytorch/pytorch-linux-trusty-py2.7.9:251
        <<: *docker_config_defaults
    environment:
      JOB_BASE_NAME: pytorch-linux-trusty-py2.7.9-build-test
    <<: *pytorch_linux_cpu_build_test_defaults

  pytorch_linux_trusty_py2_7_build_test:
    docker:
      - image: 308535385114.dkr.ecr.us-east-1.amazonaws.com/pytorch/pytorch-linux-trusty-py2.7:251
        <<: *docker_config_defaults
    environment:
      JOB_BASE_NAME: pytorch-linux-trusty-py2.7-build-test
    <<: *pytorch_linux_cpu_build_test_defaults

  pytorch_linux_trusty_py3_5_build_test:
    docker:
      - image: 308535385114.dkr.ecr.us-east-1.amazonaws.com/pytorch/pytorch-linux-trusty-py3.5:251
        <<: *docker_config_defaults
    environment:
      JOB_BASE_NAME: pytorch-linux-trusty-py3.5-build-test
    <<: *pytorch_linux_cpu_build_test_defaults

  pytorch_linux_trusty_py3_6_gcc4_8_build_test:
    docker:
      - image: 308535385114.dkr.ecr.us-east-1.amazonaws.com/pytorch/pytorch-linux-trusty-py3.6-gcc4.8:251
        <<: *docker_config_defaults
    environment:
      JOB_BASE_NAME: pytorch-linux-trusty-py3.6-gcc4.8-build-test
    <<: *pytorch_linux_cpu_build_test_defaults

  pytorch_linux_trusty_py3_6_gcc5_4_build_test:
    docker:
      - image: 308535385114.dkr.ecr.us-east-1.amazonaws.com/pytorch/pytorch-linux-trusty-py3.6-gcc5.4:251
        <<: *docker_config_defaults
    environment:
      JOB_BASE_NAME: pytorch-linux-trusty-py3.6-gcc5.4-build-test
    <<: *pytorch_linux_cpu_build_test_defaults

  pytorch_linux_trusty_py3_6_gcc7_build_test:
    docker:
      - image: 308535385114.dkr.ecr.us-east-1.amazonaws.com/pytorch/pytorch-linux-trusty-py3.6-gcc7:251
        <<: *docker_config_defaults
    environment:
      JOB_BASE_NAME: pytorch-linux-trusty-py3.6-gcc7-build-test
    <<: *pytorch_linux_cpu_build_test_defaults

  pytorch_linux_trusty_pynightly_build_test:
    docker:
      - image: 308535385114.dkr.ecr.us-east-1.amazonaws.com/pytorch/pytorch-linux-trusty-pynightly:251
        <<: *docker_config_defaults
    environment:
      JOB_BASE_NAME: pytorch-linux-trusty-pynightly-build-test
    <<: *pytorch_linux_cpu_build_test_defaults

  pytorch_linux_xenial_py3_clang5_asan_build:
    environment:
      JOB_BASE_NAME: pytorch-linux-xenial-py3-clang5-asan-build
      DOCKER_IMAGE: "308535385114.dkr.ecr.us-east-1.amazonaws.com/pytorch/pytorch-linux-xenial-py3-clang5-asan:251"
      PYTHON_VERSION: "3.6"
    <<: *pytorch_linux_build_defaults

  pytorch_linux_xenial_py3_clang5_asan_test:
    environment:
      JOB_BASE_NAME: pytorch-linux-xenial-py3-clang5-asan-test
      PYTHON_VERSION: "3.6"
    resource_class: large
    <<: *pytorch_linux_test_defaults

  pytorch_linux_xenial_cuda8_cudnn6_py3_build:
    environment:
      JOB_BASE_NAME: pytorch-linux-xenial-cuda8-cudnn6-py3-build
      DOCKER_IMAGE: "308535385114.dkr.ecr.us-east-1.amazonaws.com/pytorch/pytorch-linux-xenial-cuda8-cudnn6-py3:251"
      PYTHON_VERSION: "3.6"
      CUDA_VERSION: "8"
    <<: *pytorch_linux_build_defaults

  pytorch_linux_xenial_cuda8_cudnn6_py3_test:
    environment:
      JOB_BASE_NAME: pytorch-linux-xenial-cuda8-cudnn6-py3-test
      PYTHON_VERSION: "3.6"
      CUDA_VERSION: "8"
    resource_class: gpu.medium
    <<: *pytorch_linux_test_defaults

  pytorch_linux_xenial_cuda8_cudnn6_py3_multigpu_test:
    environment:
      JOB_BASE_NAME: pytorch-linux-xenial-cuda8-cudnn6-py3-multigpu-test
      PYTHON_VERSION: "3.6"
      CUDA_VERSION: "8"
      MULTI_GPU: "1"
    resource_class: gpu.large
    <<: *pytorch_linux_test_defaults

  pytorch_linux_xenial_cuda8_cudnn6_py3_NO_AVX2_test:
    environment:
      JOB_BASE_NAME: pytorch-linux-xenial-cuda8-cudnn6-py3-NO_AVX2-test
      PYTHON_VERSION: "3.6"
      CUDA_VERSION: "8"
    resource_class: gpu.medium
    <<: *pytorch_linux_test_defaults

  pytorch_linux_xenial_cuda8_cudnn6_py3_NO_AVX_NO_AVX2_test:
    environment:
      JOB_BASE_NAME: pytorch-linux-xenial-cuda8-cudnn6-py3-NO_AVX-NO_AVX2-test
      PYTHON_VERSION: "3.6"
      CUDA_VERSION: "8"
    resource_class: gpu.medium
    <<: *pytorch_linux_test_defaults

  pytorch_linux_xenial_cuda9_cudnn7_py2_build:
    environment:
      JOB_BASE_NAME: pytorch-linux-xenial-cuda9-cudnn7-py2-build
      DOCKER_IMAGE: "308535385114.dkr.ecr.us-east-1.amazonaws.com/pytorch/pytorch-linux-xenial-cuda9-cudnn7-py2:251"
      PYTHON_VERSION: "2.7"
      CUDA_VERSION: "9"
    <<: *pytorch_linux_build_defaults

  pytorch_linux_xenial_cuda9_cudnn7_py2_test:
    environment:
      JOB_BASE_NAME: pytorch-linux-xenial-cuda9-cudnn7-py2-test
      PYTHON_VERSION: "2.7"
      CUDA_VERSION: "9"
    resource_class: gpu.medium
    <<: *pytorch_linux_test_defaults

  pytorch_linux_xenial_cuda9_cudnn7_py3_build:
    environment:
      JOB_BASE_NAME: pytorch-linux-xenial-cuda9-cudnn7-py3-build
      DOCKER_IMAGE: "308535385114.dkr.ecr.us-east-1.amazonaws.com/pytorch/pytorch-linux-xenial-cuda9-cudnn7-py3:251"
      PYTHON_VERSION: "3.6"
      CUDA_VERSION: "9"
    <<: *pytorch_linux_build_defaults

  pytorch_linux_xenial_cuda9_cudnn7_py3_test:
    environment:
      JOB_BASE_NAME: pytorch-linux-xenial-cuda9-cudnn7-py3-test
      PYTHON_VERSION: "3.6"
      CUDA_VERSION: "9"
    resource_class: gpu.medium
    <<: *pytorch_linux_test_defaults

  pytorch_linux_xenial_cuda9_2_cudnn7_py3_gcc7_build:
    environment:
      JOB_BASE_NAME: pytorch-linux-xenial-cuda9.2-cudnn7-py3-gcc7-build
      DOCKER_IMAGE: "308535385114.dkr.ecr.us-east-1.amazonaws.com/pytorch/pytorch-linux-xenial-cuda9.2-cudnn7-py3-gcc7:251"
      PYTHON_VERSION: "3.6"
      CUDA_VERSION: "9.2"
    <<: *pytorch_linux_build_defaults

  pytorch_linux_xenial_cuda9_2_cudnn7_py3_gcc7_test:
    environment:
      JOB_BASE_NAME: pytorch-linux-xenial-cuda9.2-cudnn7-py3-gcc7-test
      PYTHON_VERSION: "3.6"
      CUDA_VERSION: "9.2"
    resource_class: gpu.medium
    <<: *pytorch_linux_test_defaults

  pytorch_short_perf_test_gpu:
    environment:
      JOB_BASE_NAME: pytorch-short-perf-test-gpu
      PYTHON_VERSION: "3.6"
      CUDA_VERSION: "8"
    resource_class: gpu.medium
    machine:
      image: default
    steps:
    - run:
        name: Prepare workspace
        command: |
          sudo mkdir -p /home/circleci/project/pytorch-ci-env
          sudo chmod -R 777 /home/circleci/project/pytorch-ci-env
    - attach_workspace:
        at: /home/circleci/project/pytorch-ci-env
    - run:
        <<: *setup_ci_environment
    - run:
        name: Perf Test
        no_output_timeout: "1h"
        command: |
          set -e
          source /home/circleci/project/pytorch-ci-env/COMMIT_DOCKER_IMAGE
          echo "DOCKER_IMAGE: "${COMMIT_DOCKER_IMAGE}
          docker pull ${COMMIT_DOCKER_IMAGE}
          id=$(docker run --runtime=nvidia -t -d -w /var/lib/jenkins ${COMMIT_DOCKER_IMAGE})

          docker cp $id:/var/lib/jenkins/workspace/env /home/circleci/project/env
          # This IAM user allows write access to S3 bucket for perf test numbers
          echo "declare -x AWS_ACCESS_KEY_ID=${CIRCLECI_AWS_ACCESS_KEY_FOR_PERF_TEST_S3_BUCKET_V2}" >> /home/circleci/project/env
          echo "declare -x AWS_SECRET_ACCESS_KEY=${CIRCLECI_AWS_SECRET_KEY_FOR_PERF_TEST_S3_BUCKET_V2}" >> /home/circleci/project/env
          docker cp /home/circleci/project/env $id:/var/lib/jenkins/workspace/env

          ((echo "export JOB_BASE_NAME=${JOB_BASE_NAME}" && echo "source ./workspace/env" && echo 'sudo chown -R jenkins workspace && cd workspace && .jenkins/pytorch/short-perf-test-gpu.sh') | docker exec -u jenkins -i "$id" bash) 2>&1 | ts

  pytorch_macos_10_13_py3_build:
    macos:
      xcode: "9.0"
    steps:
      - checkout
      - run:
          <<: *merge_pull_request_onto_master
      - run:
          name: Build
          environment:
            JOB_BASE_NAME: pytorch-macos-10.13-py3-build
            BUILD_ENVIRONMENT: pytorch-macos-10.13-py3
          no_output_timeout: "1h"
          command: |
            set -e

            export IN_CIRCLECI=1

            brew install moreutils

            # Install sccache
            sudo curl https://s3.amazonaws.com/ossci-macos/sccache --output /usr/local/bin/sccache
            sudo chmod +x /usr/local/bin/sccache

            export SCCACHE_BUCKET=ossci-compiler-cache-circleci-v2
            # This IAM user allows write access to S3 bucket for sccache
            export AWS_ACCESS_KEY_ID=${CIRCLECI_AWS_ACCESS_KEY_FOR_SCCACHE_S3_BUCKET_V2}
            export AWS_SECRET_ACCESS_KEY=${CIRCLECI_AWS_SECRET_KEY_FOR_SCCACHE_S3_BUCKET_V2}

            git submodule sync && git submodule update --init
            chmod a+x .jenkins/pytorch/macos-build.sh
            .jenkins/pytorch/macos-build.sh 2>&1 | ts

            # TODO: need to share source files from build to test, when macOS builds are enabled

      - persist_to_workspace:
          root: /Users/distiller/pytorch-ci-env
          paths:
            - "*"

  pytorch_macos_10_13_py3_test:
    macos:
      xcode: "9.0"
    steps:
      - run:
          name: Prepare workspace
          command: |
            sudo mkdir -p /Users/distiller/pytorch-ci-env
            sudo chmod -R 777 /Users/distiller/pytorch-ci-env
      - attach_workspace:
          at: /Users/distiller/pytorch-ci-env
      - run:
          name: Test
          environment:
            JOB_BASE_NAME: pytorch-macos-10.13-py3-test
            BUILD_ENVIRONMENT: pytorch-macos-10.13-py3
          no_output_timeout: "1h"
          command: |
            # TODO: need to share source files from build to test, when macOS builds are enabled
            set -e
            export IN_CIRCLECI=1
            brew install moreutils
            chmod a+x .jenkins/pytorch/macos-test.sh
            .jenkins/pytorch/macos-test.sh 2>&1 | ts

  pytorch_macos_10_13_cuda9_2_cudnn7_py3_build:
    macos:
      xcode: "9.0"
    steps:
      - checkout
      - run:
          <<: *merge_pull_request_onto_master
      - run:
          name: Build
          environment:
            JOB_BASE_NAME: pytorch-macos-10.13-cuda9.2-cudnn7-py3-build
            BUILD_ENVIRONMENT: pytorch-macos-10.13-cuda9.2-cudnn7-py3
          no_output_timeout: "1h"
          command: |
            set -e

            export IN_CIRCLECI=1

            brew install moreutils

            # Install CUDA 9.2
            sudo rm -rf ~/cuda_9.2.64_mac_installer.app || true
            curl https://s3.amazonaws.com/ossci-macos/cuda_9.2.64_mac_installer.zip -o ~/cuda_9.2.64_mac_installer.zip
            unzip ~/cuda_9.2.64_mac_installer.zip -d ~/
            sudo ~/cuda_9.2.64_mac_installer.app/Contents/MacOS/CUDAMacOSXInstaller --accept-eula --no-window
            sudo cp /usr/local/cuda/lib/libcuda.dylib /Developer/NVIDIA/CUDA-9.2/lib/libcuda.dylib
            sudo rm -rf /usr/local/cuda || true

            # Install cuDNN 7.1 for CUDA 9.2
            curl https://s3.amazonaws.com/ossci-macos/cudnn-9.2-osx-x64-v7.1.tgz -o ~/cudnn-9.2-osx-x64-v7.1.tgz
            rm -rf ~/cudnn-9.2-osx-x64-v7.1 && mkdir ~/cudnn-9.2-osx-x64-v7.1
            tar -xzvf ~/cudnn-9.2-osx-x64-v7.1.tgz -C ~/cudnn-9.2-osx-x64-v7.1
            sudo cp ~/cudnn-9.2-osx-x64-v7.1/cuda/include/cudnn.h /Developer/NVIDIA/CUDA-9.2/include/
            sudo cp ~/cudnn-9.2-osx-x64-v7.1/cuda/lib/libcudnn* /Developer/NVIDIA/CUDA-9.2/lib/
            sudo chmod a+r /Developer/NVIDIA/CUDA-9.2/include/cudnn.h /Developer/NVIDIA/CUDA-9.2/lib/libcudnn*

            # Install sccache
            sudo curl https://s3.amazonaws.com/ossci-macos/sccache --output /usr/local/bin/sccache
            sudo chmod +x /usr/local/bin/sccache
            export SCCACHE_BUCKET=ossci-compiler-cache-circleci-v2
            # This IAM user allows write access to S3 bucket for sccache
            export AWS_ACCESS_KEY_ID=${CIRCLECI_AWS_ACCESS_KEY_FOR_SCCACHE_S3_BUCKET_V2}
            export AWS_SECRET_ACCESS_KEY=${CIRCLECI_AWS_SECRET_KEY_FOR_SCCACHE_S3_BUCKET_V2}

            git submodule sync && git submodule update --init
            chmod a+x .jenkins/pytorch/macos-build.sh
            .jenkins/pytorch/macos-build.sh 2>&1 | ts

  caffe2_py2_cuda8_0_cudnn6_ubuntu16_04_build:
    environment:
      JOB_BASE_NAME: caffe2-py2-cuda8.0-cudnn6-ubuntu16.04-build
      DOCKER_IMAGE: "308535385114.dkr.ecr.us-east-1.amazonaws.com/caffe2/py2-cuda8.0-cudnn6-ubuntu16.04:213"
      CUDA_VERSION: "8"
      BUILD_ENVIRONMENT: "py2-cuda8.0-cudnn6-ubuntu16.04"
    <<: *caffe2_linux_build_defaults

  caffe2_py2_cuda8_0_cudnn6_ubuntu16_04_test:
    environment:
      JOB_BASE_NAME: caffe2-py2-cuda8.0-cudnn6-ubuntu16.04-test
      DOCKER_IMAGE: "308535385114.dkr.ecr.us-east-1.amazonaws.com/caffe2/py2-cuda8.0-cudnn6-ubuntu16.04:213"
      CUDA_VERSION: "8"
      BUILD_ENVIRONMENT: "py2-cuda8.0-cudnn6-ubuntu16.04"
    resource_class: gpu.medium
    <<: *caffe2_linux_test_defaults

  caffe2_py2_cuda9_0_cudnn7_ubuntu16_04_build:
    environment:
      JOB_BASE_NAME: caffe2-py2-cuda9.0-cudnn7-ubuntu16.04-build
      DOCKER_IMAGE: "308535385114.dkr.ecr.us-east-1.amazonaws.com/caffe2/py2-cuda9.0-cudnn7-ubuntu16.04:213"
      CUDA_VERSION: "9"
      BUILD_ENVIRONMENT: "py2-cuda9.0-cudnn7-ubuntu16.04"
    <<: *caffe2_linux_build_defaults

  caffe2_py2_cuda9_0_cudnn7_ubuntu16_04_test:
    environment:
      JOB_BASE_NAME: caffe2-py2-cuda9.0-cudnn7-ubuntu16.04-test
      DOCKER_IMAGE: "308535385114.dkr.ecr.us-east-1.amazonaws.com/caffe2/py2-cuda9.0-cudnn7-ubuntu16.04:213"
      CUDA_VERSION: "9"
      BUILD_ENVIRONMENT: "py2-cuda9.0-cudnn7-ubuntu16.04"
    resource_class: gpu.medium
    <<: *caffe2_linux_test_defaults

  caffe2_py2_cuda9_1_cudnn7_ubuntu16_04_build:
    environment:
      JOB_BASE_NAME: caffe2-py2-cuda9.1-cudnn7-ubuntu16.04-build
      DOCKER_IMAGE: "308535385114.dkr.ecr.us-east-1.amazonaws.com/caffe2/py2-cuda9.1-cudnn7-ubuntu16.04:213"
      CUDA_VERSION: "9.1"
      BUILD_ENVIRONMENT: "py2-cuda9.1-cudnn7-ubuntu16.04"
    <<: *caffe2_linux_build_defaults

  caffe2_py2_cuda9_1_cudnn7_ubuntu16_04_test:
    environment:
      JOB_BASE_NAME: caffe2-py2-cuda9.1-cudnn7-ubuntu16.04-test
      DOCKER_IMAGE: "308535385114.dkr.ecr.us-east-1.amazonaws.com/caffe2/py2-cuda9.1-cudnn7-ubuntu16.04:213"
      CUDA_VERSION: "9.1"
      BUILD_ENVIRONMENT: "py2-cuda9.1-cudnn7-ubuntu16.04"
    resource_class: gpu.medium
    <<: *caffe2_linux_test_defaults

  caffe2_py2_mkl_ubuntu16_04_build:
    environment:
      JOB_BASE_NAME: caffe2-py2-mkl-ubuntu16.04-build
      DOCKER_IMAGE: "308535385114.dkr.ecr.us-east-1.amazonaws.com/caffe2/py2-mkl-ubuntu16.04:213"
      BUILD_ENVIRONMENT: "py2-mkl-ubuntu16.04"
    <<: *caffe2_linux_build_defaults

  caffe2_py2_mkl_ubuntu16_04_test:
    environment:
      JOB_BASE_NAME: caffe2-py2-mkl-ubuntu16.04-test
      DOCKER_IMAGE: "308535385114.dkr.ecr.us-east-1.amazonaws.com/caffe2/py2-mkl-ubuntu16.04:213"
      BUILD_ENVIRONMENT: "py2-mkl-ubuntu16.04"
    resource_class: large
    <<: *caffe2_linux_test_defaults

  caffe2_py2_gcc4_8_ubuntu14_04_build:
    environment:
      JOB_BASE_NAME: caffe2-py2-gcc4.8-ubuntu14.04-build
      DOCKER_IMAGE: "308535385114.dkr.ecr.us-east-1.amazonaws.com/caffe2/py2-gcc4.8-ubuntu14.04:213"
      BUILD_ENVIRONMENT: "py2-gcc4.8-ubuntu14.04"
    <<: *caffe2_linux_build_defaults

  caffe2_py2_gcc4_8_ubuntu14_04_test:
    environment:
      JOB_BASE_NAME: caffe2-py2-gcc4.8-ubuntu14.04-test
      DOCKER_IMAGE: "308535385114.dkr.ecr.us-east-1.amazonaws.com/caffe2/py2-gcc4.8-ubuntu14.04:213"
      BUILD_ENVIRONMENT: "py2-gcc4.8-ubuntu14.04"
    resource_class: large
    <<: *caffe2_linux_test_defaults

  caffe2_onnx_py2_gcc5_ubuntu16_04_build:
    environment:
      JOB_BASE_NAME: caffe2-onnx-py2-gcc5-ubuntu16.04-build
      DOCKER_IMAGE: "308535385114.dkr.ecr.us-east-1.amazonaws.com/caffe2/py2-gcc5-ubuntu16.04:213"
      BUILD_ENVIRONMENT: "onnx-py2-gcc5-ubuntu16.04"
    <<: *caffe2_linux_build_defaults

  caffe2_onnx_py2_gcc5_ubuntu16_04_test:
    environment:
      JOB_BASE_NAME: caffe2-onnx-py2-gcc5-ubuntu16.04-test
      DOCKER_IMAGE: "308535385114.dkr.ecr.us-east-1.amazonaws.com/caffe2/py2-gcc5-ubuntu16.04:213"
      BUILD_ENVIRONMENT: "onnx-py2-gcc5-ubuntu16.04"
    resource_class: large
    <<: *caffe2_linux_test_defaults

  caffe2_py2_cuda8_0_cudnn7_ubuntu16_04_build:
    environment:
      JOB_BASE_NAME: caffe2-py2-cuda8.0-cudnn7-ubuntu16.04-build
      DOCKER_IMAGE: "308535385114.dkr.ecr.us-east-1.amazonaws.com/caffe2/py2-cuda8.0-cudnn7-ubuntu16.04:213"
      BUILD_ENVIRONMENT: "py2-cuda8.0-cudnn7-ubuntu16.04"
      BUILD_ONLY: "1"
    <<: *caffe2_linux_build_defaults

  caffe2_py2_gcc4_9_ubuntu14_04_build:
    environment:
      JOB_BASE_NAME: caffe2-py2-gcc4.9-ubuntu14.04-build
      DOCKER_IMAGE: "308535385114.dkr.ecr.us-east-1.amazonaws.com/caffe2/py2-gcc4.9-ubuntu14.04:213"
      BUILD_ENVIRONMENT: "py2-gcc4.9-ubuntu14.04"
      BUILD_ONLY: "1"
    <<: *caffe2_linux_build_defaults

  caffe2_py2_clang3_8_ubuntu16_04_build:
    environment:
      JOB_BASE_NAME: caffe2-py2-clang3.8-ubuntu16.04-build
      DOCKER_IMAGE: "308535385114.dkr.ecr.us-east-1.amazonaws.com/caffe2/py2-clang3.8-ubuntu16.04:213"
      BUILD_ENVIRONMENT: "py2-clang3.8-ubuntu16.04"
      BUILD_ONLY: "1"
    <<: *caffe2_linux_build_defaults

  caffe2_py2_clang3_9_ubuntu16_04_build:
    environment:
      JOB_BASE_NAME: caffe2-py2-clang3.9-ubuntu16.04-build
      DOCKER_IMAGE: "308535385114.dkr.ecr.us-east-1.amazonaws.com/caffe2/py2-clang3.9-ubuntu16.04:213"
      BUILD_ENVIRONMENT: "py2-clang3.9-ubuntu16.04"
      BUILD_ONLY: "1"
    <<: *caffe2_linux_build_defaults

  caffe2_py2_android_ubuntu16_04_build:
    environment:
      JOB_BASE_NAME: caffe2-py2-android-ubuntu16.04-build
      DOCKER_IMAGE: "308535385114.dkr.ecr.us-east-1.amazonaws.com/caffe2/py2-android-ubuntu16.04:213"
      BUILD_ENVIRONMENT: "py2-android-ubuntu16.04"
      BUILD_ONLY: "1"
    <<: *caffe2_linux_build_defaults

  caffe2_py2_cuda9_0_cudnn7_centos7_build:
    environment:
      JOB_BASE_NAME: caffe2-py2-cuda9.0-cudnn7-centos7-build
      DOCKER_IMAGE: "308535385114.dkr.ecr.us-east-1.amazonaws.com/caffe2/py2-cuda9.0-cudnn7-centos7:213"
      BUILD_ENVIRONMENT: "py2-cuda9.0-cudnn7-centos7"
      BUILD_ONLY: "1"
    <<: *caffe2_linux_build_defaults

  caffe2_py2_ios_macos10_13_build:
    environment:
      JOB_BASE_NAME: caffe2-py2-ios-macos10.13-build
      BUILD_IOS: "1"
      PYTHON_INSTALLATION: "system"
      PYTHON_VERSION: "2"
    <<: *caffe2_macos_build_defaults

  caffe2_py2_system_macos10_13_build:
    environment:
      JOB_BASE_NAME: caffe2-py2-system-macos10.13-build
      PYTHON_INSTALLATION: "system"
      PYTHON_VERSION: "2"
    <<: *caffe2_macos_build_defaults

workflows:
  version: 2
  build:
    jobs:
      - pytorch_linux_trusty_py2_7_9_build_test
      - pytorch_linux_trusty_py2_7_build_test
      - pytorch_linux_trusty_py3_5_build_test
      - pytorch_linux_trusty_py3_6_gcc4_8_build_test
      - pytorch_linux_trusty_py3_6_gcc5_4_build_test
      - pytorch_linux_trusty_py3_6_gcc7_build_test
      - pytorch_linux_trusty_pynightly_build_test
      - pytorch_linux_xenial_py3_clang5_asan_build
      - pytorch_linux_xenial_py3_clang5_asan_test:
          requires:
            - pytorch_linux_xenial_py3_clang5_asan_build
      - pytorch_linux_xenial_cuda8_cudnn6_py3_build
      - pytorch_linux_xenial_cuda8_cudnn6_py3_test:
          requires:
            - pytorch_linux_xenial_cuda8_cudnn6_py3_build
      - pytorch_linux_xenial_cuda8_cudnn6_py3_multigpu_test:
          requires:
            - pytorch_linux_xenial_cuda8_cudnn6_py3_build
      - pytorch_linux_xenial_cuda8_cudnn6_py3_NO_AVX2_test:
          requires:
            - pytorch_linux_xenial_cuda8_cudnn6_py3_build
      - pytorch_linux_xenial_cuda8_cudnn6_py3_NO_AVX_NO_AVX2_test:
          requires:
            - pytorch_linux_xenial_cuda8_cudnn6_py3_build
      - pytorch_short_perf_test_gpu:
          requires:
            - pytorch_linux_xenial_cuda8_cudnn6_py3_build
      - pytorch_linux_xenial_cuda9_cudnn7_py2_build
      - pytorch_linux_xenial_cuda9_cudnn7_py2_test:
          requires:
            - pytorch_linux_xenial_cuda9_cudnn7_py2_build
      - pytorch_linux_xenial_cuda9_cudnn7_py3_build
      - pytorch_linux_xenial_cuda9_cudnn7_py3_test:
          requires:
            - pytorch_linux_xenial_cuda9_cudnn7_py3_build
      - pytorch_linux_xenial_cuda9_2_cudnn7_py3_gcc7_build
      - pytorch_linux_xenial_cuda9_2_cudnn7_py3_gcc7_test:
          requires:
            - pytorch_linux_xenial_cuda9_2_cudnn7_py3_gcc7_build

      # - pytorch_macos_10_13_py3_build
      # - pytorch_macos_10_13_py3_test:
      #     requires:
      #       - pytorch_macos_10_13_py3_build
      # - pytorch_macos_10_13_cuda9_2_cudnn7_py3_build

      - caffe2_py2_cuda8_0_cudnn6_ubuntu16_04_build
      - caffe2_py2_cuda8_0_cudnn6_ubuntu16_04_test:
          requires:
            - caffe2_py2_cuda8_0_cudnn6_ubuntu16_04_build
      - caffe2_py2_cuda9_0_cudnn7_ubuntu16_04_build
      - caffe2_py2_cuda9_0_cudnn7_ubuntu16_04_test:
          requires:
            - caffe2_py2_cuda9_0_cudnn7_ubuntu16_04_build
      - caffe2_py2_cuda9_1_cudnn7_ubuntu16_04_build
      - caffe2_py2_cuda9_1_cudnn7_ubuntu16_04_test:
          requires:
            - caffe2_py2_cuda9_1_cudnn7_ubuntu16_04_build
      - caffe2_py2_mkl_ubuntu16_04_build
      - caffe2_py2_mkl_ubuntu16_04_test:
          requires:
            - caffe2_py2_mkl_ubuntu16_04_build
      - caffe2_py2_gcc4_8_ubuntu14_04_build
      - caffe2_py2_gcc4_8_ubuntu14_04_test:
          requires:
            - caffe2_py2_gcc4_8_ubuntu14_04_build
      - caffe2_onnx_py2_gcc5_ubuntu16_04_build
      - caffe2_onnx_py2_gcc5_ubuntu16_04_test:
          requires:
            - caffe2_onnx_py2_gcc5_ubuntu16_04_build
      - caffe2_py2_cuda8_0_cudnn7_ubuntu16_04_build
      - caffe2_py2_clang3_8_ubuntu16_04_build
      - caffe2_py2_clang3_9_ubuntu16_04_build
      - caffe2_py2_android_ubuntu16_04_build
      - caffe2_py2_cuda9_0_cudnn7_centos7_build

      # - caffe2_py2_ios_macos10_13_build
      # - caffe2_py2_system_macos10_13_build
